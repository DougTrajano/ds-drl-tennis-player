{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "In this notebook, I'll train an agent to solve the Tennis Environment using Unity ML-Agents.\n",
    "\n",
    "---\n",
    "\n",
    "# Index\n",
    "\n",
    "- [1. Setup the Environment](#1.-Setup-the-Environment)\n",
    "- [2. Start the Environment](#2.-Start-the-Environment)\n",
    "- [3. Examine the State and Action Spaces](#3.-Examine-the-State-and-Action-Spaces)\n",
    "- [4. Define helper functions to training session](#4.-Define-helper-functions-to-training-session)\n",
    "- [5. Training the Agent](#5.-Training-the-Agent)\n",
    "- [6. Test Agent on Environment](#6.-Test-Agent-on-Environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup the Environment\n",
    "\n",
    "<img align=\"left\" width=\"150\" src=\"https://www.nclouds.com/img/services/toolkit/sagemaker.png\"/>\n",
    "\n",
    "This notebook was developed on AWS SageMaker.\n",
    "\n",
    "The kernel used is **conda_python3**\n",
    "\n",
    "To setup this environment on SageMaker you need to run the next 3 cells.\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "from agent import Agent\n",
    "\n",
    "env_path = \"envs/Tennis_Linux/Tennis.x86_64\" # Linux\n",
    "#env_path = \"envs/Tennis_Windows_x86_64/Tennis.exe\" # Windows\n",
    "\n",
    "env = UnityEnvironment(file_name=env_path, no_graphics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define helper functions to training session\n",
    "\n",
    "Here we'll create a function that can be very helpful to teach the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_trainer(agents, n_episodes=2000, max_time_step=None, score_deque=100, print_range=10, early_stop=30, add_noise=False, save_model=True, verbose=False):\n",
    "    \"\"\"Deep Q-Learning trainer.\n",
    "    Params\n",
    "    ======\n",
    "        agents (list): List of Agent Objects\n",
    "        n_episodes (int): maximum number of training episodes.\n",
    "        max_time_step (int or None): The max time step per episode, if None, the agent will training until environment is done.\n",
    "        scores_deque (int): The len of score deque.\n",
    "        print_range (int): range to print partials results.\n",
    "        early_stop (int): Stop training when achieve a defined score respecting 10 min n_episodes.\n",
    "        add_noise (bool): If True, we'll reset at each step and add_noise at each action call.\n",
    "        save_model (bool): If True, we'll save the model weights when we solve the environment\n",
    "        verbose (bool): If verbose true, we'll print some infos on console.\n",
    "    \"\"\"\n",
    "    scores_window = deque(maxlen=score_deque)\n",
    "    scores = np.zeros(num_agents)\n",
    "    scores_episode = []\n",
    "    \n",
    "    for ep in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores = np.zeros(num_agents)\n",
    "        time_step = 0\n",
    "        training = True\n",
    "        \n",
    "        if add_noise:\n",
    "            for agent in agents:\n",
    "                agent.reset()\n",
    "\n",
    "        while training:\n",
    "            actions = np.array([agents[i].act(states[i], add_noise) for i in range(num_agents)])\n",
    "            env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "            next_states = env_info.vector_observations     # get the next state\n",
    "            rewards = env_info.rewards                     # get the reward\n",
    "            dones = env_info.local_done        \n",
    "            \n",
    "            for i in range(num_agents):\n",
    "                agents[i].step(states[i], actions[i], rewards[i], next_states[i], dones[i]) \n",
    " \n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            time_step += 1\n",
    "            \n",
    "            if isinstance(max_time_step, (int, float)):\n",
    "                if time_step >= max_time_step:\n",
    "                    training = False\n",
    "                    \n",
    "            if np.any(dones):\n",
    "                break \n",
    "                \n",
    "        score = np.mean(scores)\n",
    "        scores_window.append(score)\n",
    "        scores_episode.append(score)\n",
    "\n",
    "        if verbose:\n",
    "            print('\\rEpisode {} || Avg Score: {:.2f} || Max Score: {:.2f} || Avg Score (last {} episodes): {:.2f}'.format(ep, score, np.max(scores), score_deque, np.mean(scores_window)), end=\"\")\n",
    "            if ep % print_range == 0:\n",
    "                print('\\rEpisode {} || Avg Score: {:.2f} || Max Score: {:.2f} || Avg Score (last {} episodes): {:.2f}'.format(ep, score, np.max(scores), score_deque, np.mean(scores_window)))\n",
    "        if np.mean(scores_window) >= early_stop:\n",
    "            if verbose:\n",
    "                print('\\nEnvironment solved in {:d} episodes! || Avg Score: {:.2f}'.format(ep, np.mean(scores_window)))\n",
    "            if save_model:\n",
    "                Agent.save_model(params=agents[0].get_params())\n",
    "                \n",
    "            break\n",
    "            \n",
    "    return scores_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Agent\n",
    "\n",
    "In the next code cells, we will train the Agent to work on environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): -0.00\n",
      "Episode 200 || Avg Score: 0.05 || Max Score: 0.09 || Avg Score (last 100 episodes): 0.0110\n",
      "Episode 300 || Avg Score: 0.10 || Max Score: 0.10 || Avg Score (last 100 episodes): 0.022\n",
      "Episode 400 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.02\n",
      "Episode 500 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.02\n",
      "Episode 600 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 700 || Avg Score: 0.05 || Max Score: 0.10 || Avg Score (last 100 episodes): 0.021\n",
      "Episode 800 || Avg Score: 0.05 || Max Score: 0.10 || Avg Score (last 100 episodes): 0.022\n",
      "Episode 900 || Avg Score: 0.05 || Max Score: 0.10 || Avg Score (last 100 episodes): 0.022\n",
      "Episode 1000 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.02\n",
      "Episode 1100 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 1200 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 1300 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.00\n",
      "Episode 1400 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 1500 || Avg Score: 0.05 || Max Score: 0.09 || Avg Score (last 100 episodes): 0.010\n",
      "Episode 1600 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 1700 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 1800 || Avg Score: 0.10 || Max Score: 0.10 || Avg Score (last 100 episodes): -0.000\n",
      "Episode 1900 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.010\n",
      "Episode 2000 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 2100 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.00\n",
      "Episode 2200 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.00\n",
      "Episode 2300 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.000\n",
      "Episode 2400 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.00\n",
      "Episode 2500 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.000\n",
      "Episode 2600 || Avg Score: 0.10 || Max Score: 0.10 || Avg Score (last 100 episodes): -0.000\n",
      "Episode 2700 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): -0.00\n",
      "Episode 2800 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): -0.00\n",
      "Episode 2900 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): -0.00\n",
      "Episode 3000 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.010\n",
      "Episode 3100 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 3200 || Avg Score: 0.05 || Max Score: 0.10 || Avg Score (last 100 episodes): 0.000\n",
      "Episode 3300 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 3400 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.00\n",
      "Episode 3500 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.00\n",
      "Episode 3600 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 3700 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 3800 || Avg Score: 0.05 || Max Score: 0.09 || Avg Score (last 100 episodes): 0.011\n",
      "Episode 3900 || Avg Score: -0.00 || Max Score: 0.00 || Avg Score (last 100 episodes): 0.01\n",
      "Episode 4000 || Avg Score: 0.05 || Max Score: 0.10 || Avg Score (last 100 episodes): 0.011\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 24min 24s, sys: 8min 34s, total: 5h 32min 58s\n",
      "Wall time: 46min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "agents = [] \n",
    "for i in range(num_agents):\n",
    "    agents.append(Agent(state_size=state_size, action_size=action_size, random_seed=399, memory_size=int(1e8),\n",
    "                        batch_size=32, gamma=0.98, tau=1e-3, lr_actor=1e-4, lr_critic=1e-4, weight_decay=0.1,\n",
    "                        actor_units=(256, 256), critic_units=(256, 256)))\n",
    "    \n",
    "scores = rl_trainer(agents, n_episodes=4000, print_range=100, early_stop=0.5,\n",
    "                    add_noise=True, save_model=True, verbose=True)\n",
    "\n",
    "agent = agents[0]\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.load_model()\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Agent on Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "state = env_info.vector_observations[0]\n",
    "score = 0\n",
    "\n",
    "while True:\n",
    "    action = agent.act(state)\n",
    "    env_info = env.step(action)[brain_name]\n",
    "    next_state = env_info.vector_observations[0]\n",
    "    reward = env_info.rewards[0]\n",
    "    done = env_info.local_done[0]\n",
    "    score += reward\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
